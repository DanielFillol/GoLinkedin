# LinkedIn Visible Crawler

Um crawler web para LinkedIn que captura perfis visÃ­veis e envia convites de conexÃ£o, com interface web moderna e controle de limites semanais.

## ğŸš€ CaracterÃ­sticas

- **Interface Web Moderna**: UI responsiva com Tailwind CSS, HTMX e Alpine.js
- **Controle de Limites**: Respeita limite de 200 convites/semana por usuÃ¡rio
- **SessÃµes em MemÃ³ria**: Credenciais nÃ£o sÃ£o persistidas em disco
- **Streaming em Tempo Real**: SSE para logs e mÃ©tricas ao vivo
- **Armazenamento CSV**: Dados salvos incrementalmente
- **MultiusuÃ¡rio**: Cada sessÃ£o mantÃ©m suas prÃ³prias credenciais

## ğŸ—ï¸ Arquitetura

```
.
â”œâ”€ cmd/web/           # Servidor web principal
â”œâ”€ internal/
â”‚  â”œâ”€ ui/            # Templates HTML e SSE
â”‚  â”œâ”€ crawler/       # Motor do crawler (chromedp)
â”‚  â”œâ”€ storage/       # Armazenamento CSV e contadores
â”‚  â””â”€ http/          # Handlers e middleware
â”œâ”€ data/             # Dados persistentes (CSV, uploads)
```

## ğŸ“‹ Requisitos
- **Go 1.22+**
- **Chrome/Chromium** instalado
- **Navegador moderno** para a interface web

## ğŸ› ï¸ InstalaÃ§Ã£o

1. **Usando [BREW](https://brew.sh) (Opcional)**
```bash
brew install chromium --no-quarantine
brew install go
```


2. **Clone o repositÃ³rio**
```bash
git clone <repository-url>
cd linkedin-visible-crawler
```

3. **Instale as dependÃªncias**
```bash
go mod tidy
```


3. **Execute o servidor**
```bash
make run
# ou
go run ./cmd/web
```

4. **Acesse a interface**
```
http://localhost:8080
```

## ğŸ¯ Como Usar

### 1. Configurar Credenciais
- Acesse o primeiro card "ğŸ” Credenciais do LinkedIn"
- Digite seu email e senha do LinkedIn
- Clique em "Usar nesta sessÃ£o"

### 2. Configurar Queries
- **OpÃ§Ã£o A**: FaÃ§a upload de arquivo .txt (uma query por linha)
- **OpÃ§Ã£o B**: Cole as queries diretamente na textarea
- Exemplo de queries:
  ```
  grupo boticÃ¡rio vendas
  startup tecnologia
  consultor financeiro
  ```

### 3. Executar Crawler
- Configure limites (max cards, max convites por pÃ¡gina)
- Clique em "Iniciar Crawler"
- **Importante**: Aguarde 8 segundos para 2FA manual

### 4. Acompanhar Progresso
- **Status ao Vivo**: Contadores e barra de progresso
- **Logs em Tempo Real**: Acompanhe cada aÃ§Ã£o do crawler
- **Tabela de Convites**: Veja todos os convites enviados

## ğŸ“Š Controles e Limites

### Limite Semanal
- **200 convites por usuÃ¡rio por semana**
- Barra de progresso muda de cor conforme aproxima do limite
- BotÃ£o "Iniciar Crawler" Ã© desabilitado quando limite Ã© atingido

### ConfiguraÃ§Ãµes por PÃ¡gina
- **Max Cards**: Quantos perfis capturar por pÃ¡gina (padrÃ£o: 60)
- **Max Connects**: Quantos convites tentar por pÃ¡gina (padrÃ£o: 3)

## ğŸ”’ SeguranÃ§a

- **Credenciais em MemÃ³ria**: Senhas nunca sÃ£o salvas em disco
- **SessÃµes Ãšnicas**: Cada usuÃ¡rio tem sua prÃ³pria sessÃ£o
- **Limpeza AutomÃ¡tica**: SessÃµes expiradas sÃ£o removidas a cada hora
- **SanitizaÃ§Ã£o**: Todo output HTML Ã© escapado automaticamente

## âš ï¸ Avisos Importantes

### Termos de ServiÃ§o (ToS)
- **Este Ã© um crawler experimental**
- **Use com responsabilidade**
- **Respeite os ToS do LinkedIn**
- **NÃ£o abuse da plataforma**

### Riscos de Bloqueio
- **Limite de 200 convites/semana** Ã© uma diretriz do LinkedIn
- **Pausas entre convites** sÃ£o recomendadas
- **Modo visÃ­vel** (nÃ£o headless) Ã© mais seguro
- **Monitore logs** para detectar bloqueios

### RecomendaÃ§Ãµes
- Use pausas entre execuÃ§Ãµes
- NÃ£o execute 24/7
- Monitore mÃ©tricas de sucesso
- Tenha backup de dados importantes

## ğŸ“ Estrutura de Dados

### Arquivos CSV
```
data/invites.csv
â”œâ”€ timestamp
â”œâ”€ user_email
â”œâ”€ profile_name
â”œâ”€ profile_title
â”œâ”€ company
â”œâ”€ location
â”œâ”€ linkedin_url
â””â”€ query
```

### Uploads
```
data/uploads/queries/
â””â”€ <uuid>.txt          # Arquivos de queries temporÃ¡rios
```

## ğŸš€ Comandos DisponÃ­veis
```

### Local
```bash
make run       # Executar servidor
make build     # Construir binÃ¡rio
make dev       # Modo desenvolvimento
make clean     # Limpar arquivos
make fmt       # Formatar cÃ³digo
make tidy      # Organizar dependÃªncias
make help      # Ver todos os comandos
```

## ğŸ”§ ConfiguraÃ§Ã£o

### VariÃ¡veis de Ambiente
```bash
PORT=8080                    # Porta do servidor
CHROME_HEADLESS=false        # Modo headless do Chrome
CHROME_USER_AGENT=...        # User agent personalizado
```

### Arquivo .env
```bash
cp .env.example .env
# Edite conforme necessÃ¡rio
```

## ğŸ› Troubleshooting

### Problemas Comuns

1. **Chrome nÃ£o encontrado (Local)**
   - Instale Chrome/Chromium
   - Verifique PATH do sistema

2. **Erro de permissÃ£o**
   - Verifique permissÃµes do diretÃ³rio `data/`
   - Execute com privilÃ©gios adequados

3. **Limite semanal atingido**
   - Aguarde atÃ© a prÃ³xima semana segunda-feira
   - Use conta diferente se necessÃ¡rio

4. **Crawler trava**
   - Verifique logs em tempo real
   - Reinicie o servidor se necessÃ¡rio

### Logs
- **Console**: Logs do servidor
- **Interface Web**: Logs em tempo real via SSE
- **Arquivos**: Dados salvos em CSV

## ğŸ“ˆ Monitoramento

### MÃ©tricas em Tempo Real
- Contatos capturados na sessÃ£o
- Convites enviados na semana
- Progresso do limite semanal
- Status de execuÃ§Ã£o

### ExportaÃ§Ã£o de Dados
- **CSV**: Download completo de convites
- **PaginaÃ§Ã£o**: NavegaÃ§Ã£o por resultados

## âš¡ Performance

- **Crawler**: Executa em goroutine separada
- **UI**: AtualizaÃ§Ãµes em tempo real via SSE
- **Storage**: Append-only CSV para performance
- **SessÃµes**: Limpeza automÃ¡tica de memÃ³ria

## ğŸ”„ AtualizaÃ§Ãµes

- **Limpeza automÃ¡tica** de sessÃµes expiradas
- **Contadores semanais** resetam automaticamente
- **Logs em tempo real** para debugging
- **MÃ©tricas persistentes** via CSV

---

**âš ï¸ Lembre-se**: Este Ã© um crawler experimental. Use com responsabilidade e sempre respeite os termos de serviÃ§o do LinkedIn.
